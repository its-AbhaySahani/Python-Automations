{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.11.2-py2.py3-none-any.whl (290 kB)\n",
      "                                              0.0/290.1 kB ? eta -:--:--\n",
      "     ---                                   30.7/290.1 kB 660.6 kB/s eta 0:00:01\n",
      "     ----------                            81.9/290.1 kB 762.6 kB/s eta 0:00:01\n",
      "     ---------------------                  163.8/290.1 kB 1.1 MB/s eta 0:00:01\n",
      "     ----------------------               184.3/290.1 kB 930.9 kB/s eta 0:00:01\n",
      "     --------------------------------       245.8/290.1 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 290.1/290.1 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting Twisted>=18.9.0 (from scrapy)\n",
      "  Downloading twisted-24.3.0-py3-none-any.whl (3.2 MB)\n",
      "                                              0.0/3.2 MB ? eta -:--:--\n",
      "                                              0.1/3.2 MB 1.3 MB/s eta 0:00:03\n",
      "     -                                        0.1/3.2 MB 1.2 MB/s eta 0:00:03\n",
      "     --                                       0.2/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "     ---                                      0.3/3.2 MB 1.5 MB/s eta 0:00:02\n",
      "     ----                                     0.3/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "     -----                                    0.4/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "     ------                                   0.5/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "     -------                                  0.6/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------                                0.7/3.2 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------                                0.8/3.2 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------                               0.9/3.2 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------                             1.0/3.2 MB 1.7 MB/s eta 0:00:02\n",
      "     -------------                            1.1/3.2 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------                          1.2/3.2 MB 1.8 MB/s eta 0:00:02\n",
      "     ----------------                         1.3/3.2 MB 1.9 MB/s eta 0:00:01\n",
      "     -----------------                        1.4/3.2 MB 1.8 MB/s eta 0:00:01\n",
      "     -------------------                      1.5/3.2 MB 1.9 MB/s eta 0:00:01\n",
      "     --------------------                     1.6/3.2 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------                    1.7/3.2 MB 1.9 MB/s eta 0:00:01\n",
      "     -----------------------                  1.8/3.2 MB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------                2.0/3.2 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------              2.2/3.2 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------             2.2/3.2 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------           2.4/3.2 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------------         2.6/3.2 MB 2.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       2.7/3.2 MB 2.3 MB/s eta 0:00:01\n",
      "     ------------------------------------     2.9/3.2 MB 2.3 MB/s eta 0:00:01\n",
      "     --------------------------------------   3.0/3.2 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.2/3.2 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.2/3.2 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting cryptography>=36.0.0 (from scrapy)\n",
      "  Downloading cryptography-43.0.0-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "                                              0.0/3.1 MB ? eta -:--:--\n",
      "     --                                       0.2/3.1 MB 11.5 MB/s eta 0:00:01\n",
      "     ----                                     0.3/3.1 MB 3.9 MB/s eta 0:00:01\n",
      "     -------                                  0.6/3.1 MB 4.7 MB/s eta 0:00:01\n",
      "     --------                                 0.7/3.1 MB 3.9 MB/s eta 0:00:01\n",
      "     -------------                            1.0/3.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------                         1.3/3.1 MB 4.9 MB/s eta 0:00:01\n",
      "     -----------------                        1.4/3.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------                    1.6/3.1 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------                   1.7/3.1 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------               2.0/3.1 MB 4.6 MB/s eta 0:00:01\n",
      "     ----------------------------             2.2/3.1 MB 4.4 MB/s eta 0:00:01\n",
      "     --------------------------------         2.5/3.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------     2.8/3.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.1/3.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.1/3.1 MB 4.7 MB/s eta 0:00:00\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Downloading itemloaders-1.3.1-py3-none-any.whl (12 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
      "  Downloading pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "                                              0.0/58.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.4/58.4 kB ? eta 0:00:00\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Downloading service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Downloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Downloading zope.interface-7.0-cp311-cp311-win_amd64.whl (211 kB)\n",
      "                                              0.0/211.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 211.7/211.7 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting protego>=0.1.15 (from scrapy)\n",
      "  Downloading Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Downloading itemadapter-0.9.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapy) (65.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from scrapy) (24.0)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "                                              0.0/97.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 97.6/97.6 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting lxml>=4.4.1 (from scrapy)\n",
      "  Downloading lxml-5.2.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "                                              0.0/3.8 MB ? eta -:--:--\n",
      "     ---                                      0.3/3.8 MB 7.2 MB/s eta 0:00:01\n",
      "     --------                                 0.8/3.8 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------                             1.1/3.8 MB 6.6 MB/s eta 0:00:01\n",
      "     ---------------                          1.5/3.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------                    2.0/3.8 MB 6.8 MB/s eta 0:00:01\n",
      "     -----------------------                  2.3/3.8 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------           2.9/3.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ------------------------------------     3.5/3.8 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.8/3.8 MB 7.0 MB/s eta 0:00:00\n",
      "Collecting defusedxml>=0.7.1 (from scrapy)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->scrapy)\n",
      "  Downloading cffi-1.16.0-cp311-cp311-win_amd64.whl (181 kB)\n",
      "                                              0.0/181.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.5/181.5 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting attrs>=19.1.0 (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading attrs-24.1.0-py3-none-any.whl (63 kB)\n",
      "                                              0.0/63.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 63.9/63.9 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "                                              0.0/85.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 85.3/85.3 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "                                              0.0/181.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.2/181.2 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "                                              0.0/74.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 74.6/74.6 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting incremental>=22.10.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading twisted_iocpsupport-1.0.4-cp311-cp311-win_amd64.whl (47 kB)\n",
      "                                              0.0/47.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 47.3/47.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from Twisted>=18.9.0->scrapy) (4.10.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tldextract->scrapy) (3.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tldextract->scrapy) (2.32.3)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract->scrapy)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->scrapy)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "                                              0.0/117.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 117.6/117.6 kB 6.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.7.4)\n",
      "Installing collected packages: twisted-iocpsupport, PyDispatcher, zope.interface, w3lib, queuelib, pycparser, pyasn1, protego, lxml, jmespath, itemadapter, incremental, hyperlink, filelock, defusedxml, cssselect, constantly, attrs, requests-file, pyasn1-modules, parsel, cffi, automat, Twisted, tldextract, itemloaders, cryptography, service-identity, pyOpenSSL, scrapy\n",
      "Successfully installed PyDispatcher-2.0.7 Twisted-24.3.0 attrs-24.1.0 automat-22.10.0 cffi-1.16.0 constantly-23.10.4 cryptography-43.0.0 cssselect-1.2.0 defusedxml-0.7.1 filelock-3.15.4 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.9.0 itemloaders-1.3.1 jmespath-1.0.1 lxml-5.2.2 parsel-1.9.1 protego-0.3.1 pyOpenSSL-24.2.1 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycparser-2.22 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.11.2 service-identity-24.1.0 tldextract-5.1.2 twisted-iocpsupport-1.0.4 w3lib-2.2.1 zope.interface-7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script automat-visualize.exe is installed in 'c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts cftp.exe, ckeygen.exe, conch.exe, mailmail.exe, pyhtmlizer.exe, tkconch.exe, trial.exe, twist.exe and twistd.exe are installed in 'c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tldextract.exe is installed in 'c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script scrapy.exe is installed in 'c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting quotes_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile quotes_spider.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').get(),\n",
    "                'author': quote.css('span small::text').get(),\n",
    "                'tags': quote.css('div.tags a.tag::text').getall(),\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(href)').get()\n",
    "        if next_page is not None:\n",
    "            yield response.follow(next_page, self.parse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\Scripts\\scrapy-script.py\", line 6, in <module>\n",
      "    from scrapy.cmdline import execute\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scrapy\\__init__.py\", line 12, in <module>\n",
      "    from scrapy.spiders import Spider\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scrapy\\spiders\\__init__.py\", line 93, in <module>\n",
      "    from scrapy.spiders.crawl import CrawlSpider, Rule\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scrapy\\spiders\\crawl.py\", line 14, in <module>\n",
      "    from scrapy.utils.spider import iterate_spider_output\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scrapy\\utils\\spider.py\", line 5, in <module>\n",
      "    from scrapy.utils.defer import deferred_from_coro\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scrapy\\utils\\defer.py\", line 24, in <module>\n",
      "    from scrapy.utils.reactor import is_asyncio_reactor_installed\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\scrapy\\utils\\reactor.py\", line 5, in <module>\n",
      "    from twisted.internet import asyncioreactor, error\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\twisted\\internet\\asyncioreactor.py\", line 19, in <module>\n",
      "    from twisted.internet.posixbase import (\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\twisted\\internet\\posixbase.py\", line 19, in <module>\n",
      "    from twisted.internet import error, tcp, udp\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\twisted\\internet\\tcp.py\", line 38, in <module>\n",
      "    from twisted.internet._newtls import (\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\twisted\\internet\\_newtls.py\", line 18, in <module>\n",
      "    from twisted.protocols.tls import TLSMemoryBIOFactory, TLSMemoryBIOProtocol\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\twisted\\protocols\\tls.py\", line 40, in <module>\n",
      "    from OpenSSL.SSL import (\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\OpenSSL\\__init__.py\", line 8, in <module>\n",
      "    from OpenSSL import crypto, SSL\n",
      "  File \"E:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\OpenSSL\\crypto.py\", line 3268, in <module>\n",
      "    _lib.OpenSSL_add_all_algorithms()\n",
      "AttributeError: module 'lib' has no attribute 'OpenSSL_add_all_algorithms'\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider quotes_spider.py -o quotes.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
